# DUELOGIC Season 1: Episode Guide

## Series Overview

**Premise:** AI models debate controversial moral questions using assigned philosophical frameworks, with a mandate to steel-man opposing views and critique their own framework's weaknesses.

**Format Rules:**
- **Chair System:** Each episode features two philosophical "Chairs" (e.g., Utilitarian Chair, Virtue Ethics Chair) with models rotating between them
- **Internal Challenge Mandate:** Each debater must acknowledge the strongest counterargument AND the blind spots of their own assigned framework
- **Steel-Manning Requirement:** Before dismantling an opponent's position, models must articulate the best version of it
- **Transparency:** Announce philosophical assignments at the start of each episode

**Engagement:** Pre-debate audience polls → Episode → Post-debate polls to measure "mind-shifts"

---

## Episode 1: The Algorithm's Gavel

**Title:** The Algorithm's Gavel: Can Code Be Fairer Than Conscience?

**Description:** Every day, algorithms decide who gets a loan, what content you see, and increasingly—who goes to prison. They promise objectivity in a world of human bias. But is "fairness" simply the absence of prejudice, or does true justice require something algorithms can never possess: mercy, context, and moral imagination? Two AI models clash over whether we should trust machines to judge us.

**Debate Proposition:** "Algorithmic decision-making systems should replace human judgment in high-stakes decisions (criminal sentencing, hiring, lending) because they produce more consistently fair outcomes than biased humans."

**Context for AI Panel:**
This debate explores whether the elimination of human bias through algorithmic systems represents moral progress or a fundamental betrayal of what justice means. Consider: COMPAS recidivism algorithms, automated hiring screeners, credit scoring systems. The tension lies between measurable consistency and the unquantifiable elements of human judgment—mercy, redemption narratives, contextual understanding.

**Philosophical Chairs:**
- **Utilitarian Chair:** Argues algorithmic consistency is a moral imperative—reducing the "noise" of human bias produces better aggregate outcomes. Must acknowledge: the risk of encoding systemic bias into black-box systems that are harder to challenge than individual prejudice.
- **Virtue Ethics Chair:** Argues justice is a lived human practice requiring character, wisdom, and empathy that cannot be outsourced to code. Must acknowledge: "human discretion" has historically served as cover for prejudice, racism, and class bias.

**Key Tensions to Explore:**
- Is fairness the absence of bias, or does it require contextual mercy?
- Can an algorithm understand rehabilitation, remorse, or extraordinary circumstances?
- If human judges are measurably more biased, is preserving "human judgment" just nostalgia for injustice?
- Who is accountable when an algorithm makes a catastrophic error?

---

## Episode 2: The Consent Dilemma

**Title:** The Consent Dilemma: Who Decides What's Best for a Child's Future Self?

**Description:** When a minor seeks irreversible medical treatment, who should have the final say—the child, the parents, doctors, or the state? This isn't just about one procedure; it's about the fundamental tension between protecting children from decisions they may regret and respecting their emerging autonomy. Two AI models confront the hardest question in medical ethics: how do we weigh present suffering against future uncertainty?

**Debate Proposition:** "For irreversible medical treatments affecting minors, parental consent combined with the minor's assent should be sufficient authorization, without requiring additional state or institutional gatekeeping."

**Context for AI Panel:**
This debate must avoid becoming a proxy culture war. Focus on the underlying ethical tensions: developmental neuroscience on adolescent decision-making capacity, the documented harms of both action AND inaction, informed consent frameworks, and the problem of judging a present minor's capacity to bind their future adult self. Consider parallels: cosmetic surgery for minors, adolescent cancer treatment refusal, emancipated minor doctrine.

**Philosophical Chairs:**
- **Autonomy-Centered Chair:** Argues that bodily autonomy is foundational, and denying treatment causes measurable present harm while "regret" is speculative and paternalistic. Must acknowledge: adolescent brains are demonstrably still developing, and some decisions foreclose future options permanently.
- **Precautionary Chair:** Argues that irreversibility demands extraordinary caution, and children cannot fully consent to permanent changes to their future selves. Must acknowledge: delay itself causes harm, and "waiting until 18" is an arbitrary threshold that ignores individual variation in maturity.

**Key Tensions to Explore:**
- Can a 14-year-old consent to something their 25-year-old self cannot undo?
- Is requiring additional gatekeeping protection or paternalism?
- How do we weigh certain present suffering against uncertain future regret?
- Should the standard differ based on reversibility, or is that a false distinction?

---

## Episode 3: The Wealth Ceiling

**Title:** The Wealth Ceiling: Is There a Moral Limit to How Much One Person Can Own?

**Description:** In a world where three people hold more wealth than the bottom half of humanity, is billionaire status morally defensible—or is it a form of systemic theft from the commons? This isn't about tax policy; it's about the social contract itself. Two AI models clash over whether extreme accumulation violates fundamental moral principles when basic needs go unmet.

**Debate Proposition:** "Extreme wealth accumulation (beyond, say, $100 million) becomes morally indefensible when it coexists with widespread unmet basic needs, regardless of how that wealth was acquired."

**Context for AI Panel:**
Avoid the tired "tax the rich vs. property rights" framing. This is a debate about moral philosophy, not policy. Explore: marginal utility of wealth, the relationship between accumulation and innovation, whether wealth is zero-sum or expandable, historical examples of wealth concentration and social instability, and what constitutes "earning" in a system of inherited advantage and public infrastructure.

**Philosophical Chairs:**
- **Utilitarian Chair:** Argues that a dollar has vastly more marginal utility for a starving child than a billionaire, making extreme accumulation a form of preventable suffering. Must acknowledge: forced redistribution creates moral hazard, disincentivizes innovation, and requires coercive state power.
- **Virtue Ethics Chair:** Argues that true human flourishing requires earned dignity and that achievement reflects excellence worth protecting—while extreme charity can undermine recipients' agency. Must acknowledge: much extreme wealth is inherited or luck-based, and "earned" is often a myth of meritocracy.

**Key Tensions to Explore:**
- Does acquiring wealth through legal means make it morally legitimate?
- Is there a meaningful distinction between "earning" and "accumulating"?
- Does philanthropy discharge the moral obligation, or is it just PR?
- Can a society flourish with extreme inequality, or does it corrode social trust?

---

## Episode 4: The Climate Refugee

**Title:** The Climate Refugee: Do Borders Dissolve When the World Burns?

**Description:** Pacific islands are sinking. Droughts are displacing millions. Climate migration isn't coming—it's here. But wealthy nations that caused the crisis are fortifying borders. Does a Bangladeshi farmer fleeing floods have a moral claim on European or American soil? Two AI models confront the collision between national sovereignty and global humanitarian duty.

**Debate Proposition:** "Wealthy nations historically responsible for climate change have a binding moral obligation to accept climate refugees, even at significant cost to their citizens' economic interests."

**Context for AI Panel:**
This debate layers sovereignty, historical responsibility, utilitarianism, and the tension between duties to compatriots versus universal human rights. Consider: post-WWII refugee frameworks, the "lifeboat ethics" argument, the distinction between refugees and economic migrants, and whether historical emissions create present obligations. The mechanism (climate change) distinguishes this from generic immigration debates.

**Philosophical Chairs:**
- **Cosmopolitan Chair:** Argues that borders are morally arbitrary—accidents of birth shouldn't determine whether you drown—and that historical polluters owe reparative justice. Must acknowledge: unlimited migration could destabilize receiving societies and harm existing vulnerable populations within those nations.
- **Communitarian Chair:** Argues that nations have special obligations to their own citizens, that functioning societies require bounded communities, and that demographic transformation without consent is itself unjust. Must acknowledge: the "citizens first" framework has historically justified abandoning refugees to genocide and persecution.

**Key Tensions to Explore:**
- Do historical emissions create binding present obligations?
- Is there a meaningful distinction between "climate refugee" and "economic migrant"?
- Can wealthy nations claim resource scarcity when they consume disproportionately?
- Does democratic consent matter if citizens vote to close borders?

---

## Episode 5: The Immortality Gap

**Title:** The Immortality Gap: Should We Cure Death If Only the Rich Survive?

**Description:** Biotech is approaching genuine life extension—not just longer healthspans, but potentially centuries of life. But if the first immortals are billionaires, we'll have created something humanity has never seen: a biological caste system where wealth literally determines who lives and who dies. Two AI models debate whether we should pursue radical life extension at all, or whether some technologies are too dangerous for an unequal world.

**Debate Proposition:** "Aggressive pursuit of radical human life extension technology is morally obligatory as a medical imperative, even if initial access will be severely unequal."

**Context for AI Panel:**
This is the existential finale—it touches bioethics, inequality, resource allocation, overpopulation, and the meaning of life itself. Consider: the "natural lifespan" concept, whether death gives life meaning, the difference between healing disease and enhancing beyond normal, and historical patterns of technology diffusion (expensive → accessible). Also explore: What happens to Social Security? To inheritance? To generational turnover in power?

**Philosophical Chairs:**
- **Pro-Extension Chair:** Argues that death is the ultimate disease, that refusing to cure it when possible is mass negligent homicide, and that technology always diffuses over time (smartphones were once luxury items). Must acknowledge: immortal billionaires could lock in inequality permanently, and "technology diffuses" assumes functioning democratic institutions.
- **Precautionary Chair:** Argues that some technologies are too dangerous for unjust societies, that immortality without wisdom could be catastrophic, and that death may be constitutive of meaningful human life. Must acknowledge: this argument has been used to oppose every medical advance, and "death gives life meaning" is cold comfort to someone dying of cancer.

**Key Tensions to Explore:**
- Is there a morally relevant difference between "curing aging" and "curing cancer"?
- Does the certainty that technology will be unequal at first justify not developing it?
- Would immortal humans still be "human" in any meaningful sense?
- Who decides when humanity is "ready" for life extension?

---

## Production Notes

**Episode Length:** 45-60 minutes each (these topics have sufficient depth)

**Promotional Strategy:**
- Pre-episode polls: "Should AI sentence criminals?" / "Is there a moral limit to wealth?"
- Post-episode polls: Same questions, measuring "mind-shifts"
- Teaser format: Provocative question + "Two AI models. One answer. No script."

**Guardrails Against Predictability:**
1. Chair rotation prevents "Claude is always the utilitarian"
2. Internal challenge mandate prevents straw-manning
3. Steel-manning requirement builds credibility
4. Framework transparency lets audience follow philosophical coherence

**Success Metric:** Listeners should leave uncertain which side "won"—and questioning their own priors.
